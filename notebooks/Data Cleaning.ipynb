{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "producing sign mappings from the OCHRE sign list and Susanne's recommendations. Originally, data cleaning was built into the initial Luigi workflow, but it's better to do it all at once and then feed in the correct labels to the training workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    }
   ],
   "source": [
    "archive = h5py.File(\"/local/ecw/deepscribe-data/pfa/a_pfa.h5\", \"r\")\n",
    "all_signs = list(archive.keys())\n",
    "print(len(all_signs))\n",
    "archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 unique signs remaining\n"
     ]
    }
   ],
   "source": [
    "# remove whitespace\n",
    "no_whitespace = [sign.strip() for sign in all_signs]\n",
    "# load OCHRE sign list map for crude transformation\n",
    "with open(\"/local/ecw/deepscribe/notebooks/readings_to_signs.json\") as infile:\n",
    "    reading_map = json.load(infile)\n",
    "\n",
    "readings_mapped = [reading_map.get(sign, sign) for sign in no_whitespace]\n",
    "print(f\"{len(np.unique(readings_mapped))} unique signs remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 unique signs remaining\n"
     ]
    }
   ],
   "source": [
    "# additional rules from Susanne's email on 6/25/2020\n",
    "additional_rules = {}\n",
    "# map from old sign -> correct sign\n",
    "additional_rules[\"HAL\"] = \"ḪAL\"\n",
    "additional_rules[\"na\"] = \"NA\"\n",
    "additional_rules[\"hal\"] = \"ḪAL\"\n",
    "additional_rules[\"GEŠ\"] = \"GIŠ\"\n",
    "additional_rules[\"1\"] = \"DIŠ\"\n",
    "additional_rules[\"2\"] = \"MIN\"\n",
    "additional_rules[\"10\"] = \"U\"\n",
    "additional_rules[\"20\"] = \"MAN\"\n",
    "\n",
    "# additional rules from Eddie's extrapolations\n",
    "additional_rules[\"HA\"] = \"ḪA\"\n",
    "additional_rules[\"ha\"] = \"ḪA\"\n",
    "additional_rules[\"hu\"] = \"ḪU\" #from ḫu\n",
    "\n",
    "# additional rules from correcting Unicode errors \n",
    "additional_rules[\"N÷TA\"] = \"NÍTA\"\n",
    "additional_rules[\"P÷R\"] = \"PÍR\" # double-check this. \n",
    "additional_rules[\"Z÷D\"] = \"ZÍD\" # double-check this. \n",
    "\n",
    "additional_rules[\"m°n\"] = \"SAL\" # from \"mín\"\n",
    "additional_rules[\"p°r\"] = \"PÍR\" # from pír\n",
    "additional_rules[\"°b\"] = \"TUM\" #from íb\n",
    "additional_rules[\"°p\"] = \"TUM\" #from íp\n",
    "additional_rules[\"z°\"] = \"ZÍ\" # from zí\n",
    "\n",
    "additional_rules[\"k†n\"] = \"GÁN\" # from kán\n",
    "additional_rules[\"p†r\"] = \"BAR\"# from pár\n",
    "additional_rules[\"r†b\"] = \"GAL\"# from ráb\n",
    "additional_rules[\"r†p\"] = \"GAL\"# from ráp\n",
    "\n",
    "additional_rules[\"k£m\"] = \"NE\" # from kúm\n",
    "additional_rules[\"£\"] = \"Ú\" #from ú\n",
    "\n",
    "\n",
    "rules_applied = [additional_rules.get(sign, sign) for sign in readings_mapped]\n",
    "print(f\"{len(np.unique(rules_applied))} unique signs remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# producing final sign map\n",
    "final_map = {original:transformed for original, transformed in zip(all_signs, rules_applied)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping readings to signs: 100%|██████████| 278/278 [05:46<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# transforming signs in dataset\n",
    "\n",
    "\n",
    "new_archive = h5py.File(\"/local/ecw/deepscribe-data/pfa/a_pfa_cleaned.h5\", \"w\")\n",
    "\n",
    "original_archive = h5py.File(\"/local/ecw/deepscribe-data/pfa/a_pfa.h5\", \"r\")\n",
    "\n",
    "for label in tqdm(\n",
    "    original_archive.keys(), desc=\"Mapping readings to signs\"\n",
    "):\n",
    "    \n",
    "    sign_name = final_map[label.strip()]\n",
    "    group = new_archive.require_group(sign_name)\n",
    "    # assigning all images to the same group\n",
    "    for img in original_archive[label].keys():\n",
    "        npy_img = np.array(original_archive[label][img])\n",
    "        new_dset = group.create_dataset(img, data=npy_img)\n",
    "\n",
    "        for key, val in original_archive[label][img].attrs.items():\n",
    "            new_dset.attrs[key] = val\n",
    "\n",
    "new_archive.close()\n",
    "original_archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepscribe] *",
   "language": "python",
   "name": "conda-env-deepscribe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
